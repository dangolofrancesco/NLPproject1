{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1511c8cc",
   "metadata": {},
   "source": [
    "# LLM Prompting Analysis for Emotion Intensity, Empathy, and Polarity\n",
    "\n",
    "This notebook performs LLM-based analysis using three different prompting strategies:\n",
    "- Zero-Shot Prompting\n",
    "- Few-Shot Prompting\n",
    "- Chain-of-Thought Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7828b5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), '..', 'Scripts'))\n",
    "from llm_prompting import zero_shot_prompt, few_shot_prompt, chain_of_thought_prompt, analyze_with_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ed5028",
   "metadata": {},
   "source": [
    "## Load Conversations from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8265218f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 conversations\n",
      "  Conversation 1: 22 turns\n",
      "  Conversation 2: 21 turns\n",
      "  Conversation 3: 25 turns\n",
      "  Conversation 4: 31 turns\n",
      "  Conversation 5: 20 turns\n"
     ]
    }
   ],
   "source": [
    "def load_conversations_from_dataset(dataset_path, num_conversations=5, min_utterances=10):\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    \n",
    "    conversations_data = []\n",
    "    conversation_ids = df['conversation_id'].unique()\n",
    "    \n",
    "    for conv_id in conversation_ids[:num_conversations]:\n",
    "        conv_df = df[df['conversation_id'] == conv_id].sort_values('turn_id')\n",
    "        \n",
    "        if len(conv_df) >= min_utterances:\n",
    "            utterances = []\n",
    "            labels = []\n",
    "            \n",
    "            for _, row in conv_df.iterrows():\n",
    "                utterances.append(f\"{row['speaker']}: {row['text']}\")\n",
    "                labels.append({\n",
    "                    'emotion_intensity': row['Emotion'],\n",
    "                    'empathy': row['Empathy'],\n",
    "                    'polarity': row['EmotionalPolarity']\n",
    "                })\n",
    "            \n",
    "            article_id = conv_df['article_id'].iloc[0]\n",
    "            \n",
    "            conversations_data.append({\n",
    "                'id': int(conv_id),\n",
    "                'article_id': int(article_id),\n",
    "                'utterances': utterances,\n",
    "                'ground_truth_labels': labels,\n",
    "                'num_turns': len(utterances)\n",
    "            })\n",
    "    \n",
    "    return conversations_data\n",
    "\n",
    "DATASET_PATH = '../Dataset/trac2_CONVT_train.csv'\n",
    "CONVERSATIONS = load_conversations_from_dataset(DATASET_PATH, num_conversations=5, min_utterances=10)\n",
    "\n",
    "print(f\"Loaded {len(CONVERSATIONS)} conversations\")\n",
    "for conv in CONVERSATIONS:\n",
    "    print(f\"  Conversation {conv['id']}: {conv['num_turns']} turns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f97e9c3",
   "metadata": {},
   "source": [
    "## Run Analysis on All Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ba79281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_analysis():\n",
    "    results = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"model\": \"llama-3.3-70b-versatile\",\n",
    "        \"conversations\": []\n",
    "    }\n",
    "    \n",
    "    prompting_strategies = [\n",
    "        (\"Zero-Shot\", zero_shot_prompt),\n",
    "        (\"Few-Shot\", few_shot_prompt),\n",
    "        (\"Chain-of-Thought\", chain_of_thought_prompt)\n",
    "    ]\n",
    "    \n",
    "    output_lines = []\n",
    "    output_lines.append(\"=\"*80)\n",
    "    output_lines.append(\"LLM PROMPTING ANALYSIS FOR EMOTION INTENSITY, EMPATHY, AND POLARITY\")\n",
    "    output_lines.append(f\"Model: llama-3.3-70b-versatile via Groq API\")\n",
    "    output_lines.append(f\"Timestamp: {results['timestamp']}\")\n",
    "    output_lines.append(f\"Dataset: WASSA 2024 Track 2 (trac2_CONVT_train.csv)\")\n",
    "    output_lines.append(\"=\"*80)\n",
    "    output_lines.append(\"\")\n",
    "    \n",
    "    for conv in CONVERSATIONS:\n",
    "        print(f\"\\nProcessing Conversation {conv['id']}...\")\n",
    "        conv_result = {\n",
    "            \"id\": conv['id'],\n",
    "            \"article_id\": conv['article_id'],\n",
    "            \"num_turns\": conv['num_turns'],\n",
    "            \"utterances\": conv['utterances'],\n",
    "            \"ground_truth_labels\": conv['ground_truth_labels'],\n",
    "            \"analyses\": {}\n",
    "        }\n",
    "        \n",
    "        output_lines.append(f\"\\n{'='*80}\")\n",
    "        output_lines.append(f\"CONVERSATION {conv['id']}\")\n",
    "        output_lines.append(f\"Article ID: {conv['article_id']} | Turns: {conv['num_turns']}\")\n",
    "        output_lines.append(f\"{'='*80}\")\n",
    "        output_lines.append(\"\\nUtterances:\")\n",
    "        for i, utt in enumerate(conv['utterances'], 1):\n",
    "            output_lines.append(f\"  {i}. {utt}\")\n",
    "        \n",
    "        output_lines.append(\"\\nGround Truth Labels (from dataset):\")\n",
    "        for i, label in enumerate(conv['ground_truth_labels'], 1):\n",
    "            output_lines.append(f\"  Turn {i}: Emotion={label['emotion_intensity']}, Empathy={label['empathy']}, Polarity={label['polarity']}\")\n",
    "        output_lines.append(\"\")\n",
    "        \n",
    "        for strategy_name, strategy_func in prompting_strategies:\n",
    "            print(f\"  - Running {strategy_name} prompting...\")\n",
    "            prompt = strategy_func(conv)\n",
    "            response = analyze_with_llm(prompt)\n",
    "            \n",
    "            conv_result[\"analyses\"][strategy_name] = {\n",
    "                \"prompt\": prompt,\n",
    "                \"response\": response\n",
    "            }\n",
    "            \n",
    "            output_lines.append(f\"\\n{'-'*80}\")\n",
    "            output_lines.append(f\"{strategy_name} Prompting\")\n",
    "            output_lines.append(f\"{'-'*80}\")\n",
    "            output_lines.append(\"\\nPrompt:\")\n",
    "            output_lines.append(prompt)\n",
    "            output_lines.append(\"\\nResponse:\")\n",
    "            output_lines.append(response)\n",
    "            output_lines.append(\"\")\n",
    "        \n",
    "        results[\"conversations\"].append(conv_result)\n",
    "    \n",
    "    output_file = \"../LLM_output.txt\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"\\n\".join(output_lines))\n",
    "    \n",
    "    print(f\"\\nAnalysis complete! Results saved to {output_file}\")\n",
    "    \n",
    "    json_file = \"../LLM_output.json\"\n",
    "    with open(json_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"Structured results saved to {json_file}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c200568",
   "metadata": {},
   "source": [
    "## Execute Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f7eeca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LLM prompting analysis...\n",
      "Make sure GROQ_API_KEY environment variable is set!\n",
      "\n",
      "\n",
      "Processing Conversation 1...\n",
      "  - Running Zero-Shot prompting...\n",
      "  - Running Few-Shot prompting...\n",
      "  - Running Chain-of-Thought prompting...\n",
      "\n",
      "Processing Conversation 2...\n",
      "  - Running Zero-Shot prompting...\n",
      "  - Running Few-Shot prompting...\n",
      "  - Running Chain-of-Thought prompting...\n",
      "\n",
      "Processing Conversation 3...\n",
      "  - Running Zero-Shot prompting...\n",
      "  - Running Few-Shot prompting...\n",
      "  - Running Chain-of-Thought prompting...\n",
      "\n",
      "Processing Conversation 4...\n",
      "  - Running Zero-Shot prompting...\n",
      "  - Running Few-Shot prompting...\n",
      "  - Running Chain-of-Thought prompting...\n",
      "\n",
      "Processing Conversation 5...\n",
      "  - Running Zero-Shot prompting...\n",
      "  - Running Few-Shot prompting...\n",
      "  - Running Chain-of-Thought prompting...\n",
      "\n",
      "Analysis complete! Results saved to ../LLM_output.txt\n",
      "Structured results saved to ../LLM_output.json\n",
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "Total conversations analyzed: 5\n",
      "Prompting strategies used: Zero-Shot, Few-Shot, Chain-of-Thought\n",
      "Total API calls made: 15\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting LLM prompting analysis...\")\n",
    "print(\"Make sure GROQ_API_KEY environment variable is set!\\n\")\n",
    "\n",
    "results = run_analysis()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total conversations analyzed: {len(CONVERSATIONS)}\")\n",
    "print(f\"Prompting strategies used: Zero-Shot, Few-Shot, Chain-of-Thought\")\n",
    "print(f\"Total API calls made: {len(CONVERSATIONS) * 3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f894774",
   "metadata": {},
   "source": [
    "## View Sample Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f7c5527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First conversation analysis sample:\n",
      "\n",
      "Conversation ID: 1\n",
      "Article ID: 35\n",
      "Number of turns: 22\n",
      "\n",
      "Zero-Shot Response:\n",
      "```json\n",
      "{\n",
      "  \"emotion_intensity\": 4,\n",
      "  \"empathy\": 5,\n",
      "  \"polarity\": 2,\n",
      "  \"reasoning\": \"The conversation revolves around a sad article about people struggling with natural disasters and poverty. Both persons express sadness, frustration, and disappointment, indicating a high emotion intensity score of 4. The empathy score is 5 because both persons are able to put themselves in the shoes of those struggling, expressing feelings of sadness and frustration on their behalf. They also show understanding and compassion towards the people affected. The polarity is negative (2) because the overall tone of the conversation is somber and critical, discussing the struggles and injustices faced by certain communities. However, there are also moments of hope and optimism, particularly when discussing the potential for positive change with the new generation of leaders.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(\"First conversation analysis sample:\")\n",
    "print(f\"\\nConversation ID: {results['conversations'][0]['id']}\")\n",
    "print(f\"Article ID: {results['conversations'][0]['article_id']}\")\n",
    "print(f\"Number of turns: {results['conversations'][0]['num_turns']}\")\n",
    "print(f\"\\nZero-Shot Response:\")\n",
    "print(results['conversations'][0]['analyses']['Zero-Shot']['response'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
