{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d08b8c69",
   "metadata": {
    "id": "d08b8c69"
   },
   "source": [
    "# LSTM Model - Emotion and Empathy Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590d3d9f",
   "metadata": {
    "id": "590d3d9f"
   },
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wf0Ea0aJr23Y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "wf0Ea0aJr23Y",
    "outputId": "b378c1ca-faa5-4027-915a-d1fbb9e78df0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.2)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.1)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (1.17.3)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement re (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for re\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.1)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install pandas\n",
    "!pip install gensim\n",
    "!pip install re\n",
    "!pip install numpy\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd88f38c",
   "metadata": {
    "id": "bd88f38c"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix, classification_report, mean_absolute_error, mean_squared_error, r2_score\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d03ff06",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8d03ff06",
    "outputId": "09845a2b-913b-417b-8edc-159e440be37b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Setup completed\n",
      "Root Path: /content/drive/MyDrive/NLPproject1\n",
      "Scripts Path: /content/drive/MyDrive/NLPproject1/Scripts\n",
      "Data Path: /content/drive/MyDrive/NLPproject1/Dataset\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "# This cell works only on colab  #\n",
    "##################################\n",
    "import sys\n",
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "DRIVE_NAME = \"NLPproject1\"\n",
    "ROOT_PATH = os.path.join('/content/drive/MyDrive/', DRIVE_NAME)\n",
    "SCRIPTS_PATH = f'{ROOT_PATH}/Scripts'\n",
    "DATA_PATH = f'{ROOT_PATH}/Dataset'\n",
    "\n",
    "if SCRIPTS_PATH not in sys.path:\n",
    "    sys.path.append(SCRIPTS_PATH)\n",
    "\n",
    "from preprocessing import GloveSequenceEmbedder\n",
    "from dataset import RNNEmpathyDataset, RNNInferenceDataset\n",
    "from lstm_model import LSTMEmpathyNet\n",
    "\n",
    "print(\"Setup completed\")\n",
    "print(f\"Root Path: {ROOT_PATH}\")\n",
    "print(f\"Scripts Path: {SCRIPTS_PATH}\")\n",
    "print(f\"Data Path: {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862f2d6f",
   "metadata": {
    "id": "862f2d6f"
   },
   "source": [
    "## Initialize GloVe Sequence Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f10ce988",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f10ce988",
    "outputId": "f53ce640-79e0-4cd6-8dad-152e493f7bc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing GloVe Sequence Embedder...\n",
      "Loading GloVe model 'glove-wiki-gigaword-100' for sequence embedding...\n",
      "[==================================================] 100.0% 128.1/128.1MB downloaded\n",
      "GloVe sequence model loaded successfully. Max length: 50\n",
      "Sequence Embedder initialized\n",
      "Vector size: 100\n",
      "Max length: 50\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing GloVe Sequence Embedder...\")\n",
    "sequence_embedder = GloveSequenceEmbedder(\n",
    "    model_name=\"glove-wiki-gigaword-100\",\n",
    "    max_length=50\n",
    ")\n",
    "\n",
    "print(f\"Sequence Embedder initialized\")\n",
    "print(f\"Vector size: {sequence_embedder.vector_size}\")\n",
    "print(f\"Max length: {sequence_embedder.max_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73585e84",
   "metadata": {
    "id": "73585e84"
   },
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afe4f52d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afe4f52d",
    "outputId": "0bed9b0e-70c2-4bcb-d4a0-61f2c5d39520"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss functions configured\n"
     ]
    }
   ],
   "source": [
    "regression_loss = nn.MSELoss()\n",
    "classification_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "loss_weights = {\n",
    "    'intensity': 0.2,\n",
    "    'empathy': 0.2,\n",
    "    'polarity': 0.6\n",
    "}\n",
    "\n",
    "loss_functions = {\n",
    "    'regression': regression_loss,\n",
    "    'classification': classification_loss\n",
    "}\n",
    "\n",
    "print(\"Loss functions configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef44d76f",
   "metadata": {
    "id": "ef44d76f"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7dba81f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7dba81f",
    "outputId": "4aa12844-ce18-423e-efcd-e63cc61c4d2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating LSTM datasets...\n",
      "Loaded and cleaned data from /content/drive/MyDrive/NLPproject1/Dataset/trac2_CONVT_train.csv. Number of samples: 11090\n",
      "Generating sequence embeddings for 11090 samples...\n",
      "Warning: The '3' polarity class is not present in this dataset.\n",
      "Loaded and cleaned data from /content/drive/MyDrive/NLPproject1/Dataset/trac2_CONVT_dev.csv. Number of samples: 987\n",
      "Generating sequence embeddings for 987 samples...\n",
      "Training samples: 11090\n",
      "Evaluation samples: 987\n"
     ]
    }
   ],
   "source": [
    "train_csv_path = f\"{DATA_PATH}/trac2_CONVT_train.csv\"\n",
    "eval_csv_path = f\"{DATA_PATH}/trac2_CONVT_dev.csv\"\n",
    "\n",
    "print(\"Creating LSTM datasets...\")\n",
    "lstm_train_dataset = RNNEmpathyDataset(train_csv_path, sequence_embedder)\n",
    "lstm_eval_dataset = RNNEmpathyDataset(eval_csv_path, sequence_embedder)\n",
    "\n",
    "LSTM_BATCH_SIZE = 32\n",
    "lstm_train_loader = DataLoader(lstm_train_dataset, batch_size=LSTM_BATCH_SIZE, shuffle=True)\n",
    "lstm_eval_loader = DataLoader(lstm_eval_dataset, batch_size=LSTM_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(lstm_train_dataset)}\")\n",
    "print(f\"Evaluation samples: {len(lstm_eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c154cc08",
   "metadata": {
    "id": "c154cc08"
   },
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d3b4f7a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1d3b4f7a",
    "outputId": "a63fe181-f596-420b-dc35-7d15446cd455"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured 4 LSTM experiments\n"
     ]
    }
   ],
   "source": [
    "lstm_experiment_configs = [\n",
    "    {\n",
    "        \"experiment_name\": \"lstm_baseline_h128_d0.3\",\n",
    "        \"input_dim\": sequence_embedder.vector_size,\n",
    "        \"hidden_dim\": 128,\n",
    "        \"num_layers\": 2,\n",
    "        \"bidirectional\": True,\n",
    "        \"dropout\": 0.3,\n",
    "        \"num_classes\": 4,\n",
    "        \"learning_rate\": 1e-3,\n",
    "    },\n",
    "    {\n",
    "        \"experiment_name\": \"lstm_deep_h256_d0.5\",\n",
    "        \"input_dim\": sequence_embedder.vector_size,\n",
    "        \"hidden_dim\": 256,\n",
    "        \"num_layers\": 3,\n",
    "        \"bidirectional\": True,\n",
    "        \"dropout\": 0.5,\n",
    "        \"num_classes\": 4,\n",
    "        \"learning_rate\": 5e-4,\n",
    "    },\n",
    "    {\n",
    "        \"experiment_name\": \"lstm_unidirectional_h128_d0.2\",\n",
    "        \"input_dim\": sequence_embedder.vector_size,\n",
    "        \"hidden_dim\": 128,\n",
    "        \"num_layers\": 2,\n",
    "        \"bidirectional\": False,\n",
    "        \"dropout\": 0.2,\n",
    "        \"num_classes\": 4,\n",
    "        \"learning_rate\": 1e-3,\n",
    "    },\n",
    "    {\n",
    "        \"experiment_name\": \"lstm_wide_h512_d0.4\",\n",
    "        \"input_dim\": sequence_embedder.vector_size,\n",
    "        \"hidden_dim\": 512,\n",
    "        \"num_layers\": 2,\n",
    "        \"bidirectional\": True,\n",
    "        \"dropout\": 0.4,\n",
    "        \"num_classes\": 4,\n",
    "        \"learning_rate\": 1e-4,\n",
    "    }\n",
    "]\n",
    "\n",
    "NUM_LSTM_EPOCHS = 15\n",
    "LSTM_MODELS_SAVE_PATH = f\"{ROOT_PATH}/Saved Models/LSTM\"\n",
    "os.makedirs(LSTM_MODELS_SAVE_PATH, exist_ok=True)\n",
    "\n",
    "print(f\"Configured {len(lstm_experiment_configs)} LSTM experiments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b2b663",
   "metadata": {
    "id": "b6b2b663"
   },
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c05d03f",
   "metadata": {
    "id": "1c05d03f"
   },
   "outputs": [],
   "source": [
    "def train_lstm_one_epoch(model, dataloader, optimizer, loss_fns, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    loss_weights = {'intensity': 0.2, 'empathy': 0.2, 'polarity': 0.6}\n",
    "\n",
    "    for batch in dataloader:\n",
    "        features = batch['features'].to(device)\n",
    "        # Calculate lengths based on features (assuming 0 is padding)\n",
    "        lengths = (features.sum(dim=2) != 0).sum(dim=1).to(device)\n",
    "        # Ensure lengths are at least 1\n",
    "        lengths = torch.clamp(lengths, min=1)\n",
    "        labels = {k: v.to(device) for k, v in batch['labels'].items()}\n",
    "\n",
    "        outputs = model(features, lengths)\n",
    "\n",
    "        loss_intensity = loss_fns['regression'](outputs['intensity'], labels['intensity'])\n",
    "        loss_empathy = loss_fns['regression'](outputs['empathy'], labels['empathy'])\n",
    "        loss_polarity = loss_fns['classification'](outputs['polarity'], labels['polarity'])\n",
    "\n",
    "        combined_loss = (loss_weights['intensity'] * loss_intensity +\n",
    "                        loss_weights['empathy'] * loss_empathy +\n",
    "                        loss_weights['polarity'] * loss_polarity)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        combined_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += combined_loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def evaluate_lstm_performance(model, dataloader, loss_fns, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    loss_weights = {'intensity': 0.2, 'empathy': 0.2, 'polarity': 0.6}\n",
    "\n",
    "    all_intensity_preds, all_intensity_labels = [], []\n",
    "    all_empathy_preds, all_empathy_labels = [], []\n",
    "    all_polarity_preds, all_polarity_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            features = batch['features'].to(device)\n",
    "            # Calculate lengths based on features (assuming 0 is padding)\n",
    "            lengths = (features.sum(dim=2) != 0).sum(dim=1).to(device)\n",
    "            # Ensure lengths are at least 1\n",
    "            lengths = torch.clamp(lengths, min=1)\n",
    "            labels = {k: v.to(device) for k, v in batch['labels'].items()}\n",
    "\n",
    "            outputs = model(features, lengths)\n",
    "\n",
    "            loss_intensity = loss_fns['regression'](outputs['intensity'], labels['intensity'])\n",
    "            loss_empathy = loss_fns['regression'](outputs['empathy'], labels['empathy'])\n",
    "            loss_polarity = loss_fns['classification'](outputs['polarity'], labels['polarity'])\n",
    "            combined_loss = (loss_weights['intensity'] * loss_intensity +\n",
    "                            loss_weights['empathy'] * loss_empathy +\n",
    "                            loss_weights['polarity'] * loss_polarity)\n",
    "            total_loss += combined_loss.item()\n",
    "\n",
    "            all_intensity_preds.append(outputs['intensity'].cpu())\n",
    "            all_intensity_labels.append(labels['intensity'].cpu())\n",
    "            all_empathy_preds.append(outputs['empathy'].cpu())\n",
    "            all_empathy_labels.append(labels['empathy'].cpu())\n",
    "\n",
    "            polarity_preds = torch.argmax(outputs['polarity'], dim=1)\n",
    "            all_polarity_preds.append(polarity_preds.cpu())\n",
    "            all_polarity_labels.append(labels['polarity'].cpu())\n",
    "\n",
    "    all_intensity_preds = torch.cat(all_intensity_preds)\n",
    "    all_intensity_labels = torch.cat(all_intensity_labels)\n",
    "    all_empathy_preds = torch.cat(all_empathy_preds)\n",
    "    all_empathy_labels = torch.cat(all_empathy_labels)\n",
    "    all_polarity_preds = torch.cat(all_polarity_preds)\n",
    "    all_polarity_labels = torch.cat(all_polarity_labels)\n",
    "\n",
    "    mae_intensity = nn.functional.l1_loss(all_intensity_preds, all_intensity_labels).item()\n",
    "    mae_empathy = nn.functional.l1_loss(all_empathy_preds, all_empathy_labels).item()\n",
    "\n",
    "    accuracy_polarity = accuracy_score(all_polarity_labels, all_polarity_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_polarity_labels, all_polarity_preds, average='weighted', zero_division=0\n",
    "    )\n",
    "\n",
    "    metrics = {\n",
    "        \"val_loss\": total_loss / len(dataloader),\n",
    "        \"intensity_mae\": mae_intensity,\n",
    "        \"empathy_mae\": mae_empathy,\n",
    "        \"polarity_accuracy\": accuracy_polarity,\n",
    "        \"polarity_precision\": precision,\n",
    "        \"polarity_recall\": recall,\n",
    "        \"polarity_f1\": f1\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b59c24",
   "metadata": {
    "id": "04b59c24"
   },
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49d7f819",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49d7f819",
    "outputId": "76356df5-867b-416e-8ef2-a90274cce844"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "==================================================\n",
      "Experiment: lstm_baseline_h128_d0.3\n",
      "Parameters: 632,326\n",
      "Epoch 1/15 -> Train: 0.8398 | Val: 0.7671 | F1: 0.6032\n",
      "Epoch 2/15 -> Train: 0.6924 | Val: 0.7335 | F1: 0.6498\n",
      "Epoch 3/15 -> Train: 0.6567 | Val: 0.7100 | F1: 0.6712\n",
      "Epoch 4/15 -> Train: 0.6379 | Val: 0.7158 | F1: 0.6757\n",
      "Epoch 5/15 -> Train: 0.6196 | Val: 0.7000 | F1: 0.6815\n",
      "Epoch 6/15 -> Train: 0.6030 | Val: 0.7112 | F1: 0.6588\n",
      "Epoch 7/15 -> Train: 0.5877 | Val: 0.7160 | F1: 0.6536\n",
      "Epoch 8/15 -> Train: 0.5684 | Val: 0.7099 | F1: 0.6754\n",
      "Epoch 9/15 -> Train: 0.5311 | Val: 0.7313 | F1: 0.6652\n",
      "Epoch 10/15 -> Train: 0.5134 | Val: 0.7527 | F1: 0.6542\n",
      "Early stopping at epoch 10\n",
      "New best model: lstm_baseline_h128_d0.3\n",
      "\n",
      "==================================================\n",
      "Experiment: lstm_deep_h256_d0.5\n",
      "Parameters: 3,890,182\n",
      "Epoch 1/15 -> Train: 0.8621 | Val: 0.7742 | F1: 0.6019\n",
      "Epoch 2/15 -> Train: 0.7046 | Val: 0.7595 | F1: 0.6317\n",
      "Epoch 3/15 -> Train: 0.6765 | Val: 0.7279 | F1: 0.6457\n",
      "Epoch 4/15 -> Train: 0.6569 | Val: 0.7155 | F1: 0.6472\n",
      "Epoch 5/15 -> Train: 0.6437 | Val: 0.7140 | F1: 0.6783\n",
      "Epoch 6/15 -> Train: 0.6287 | Val: 0.7237 | F1: 0.6645\n",
      "Epoch 7/15 -> Train: 0.6210 | Val: 0.7016 | F1: 0.6650\n",
      "Epoch 8/15 -> Train: 0.6007 | Val: 0.7131 | F1: 0.6766\n",
      "Epoch 9/15 -> Train: 0.5914 | Val: 0.7210 | F1: 0.6872\n",
      "Epoch 10/15 -> Train: 0.5719 | Val: 0.7180 | F1: 0.6846\n",
      "Epoch 11/15 -> Train: 0.5386 | Val: 0.7515 | F1: 0.6747\n",
      "Epoch 12/15 -> Train: 0.5206 | Val: 0.7684 | F1: 0.6565\n",
      "Early stopping at epoch 12\n",
      "\n",
      "==================================================\n",
      "Experiment: lstm_unidirectional_h128_d0.2\n",
      "Parameters: 250,630\n",
      "Epoch 1/15 -> Train: 0.8665 | Val: 0.7916 | F1: 0.5716\n",
      "Epoch 2/15 -> Train: 0.7041 | Val: 0.7247 | F1: 0.6754\n",
      "Epoch 3/15 -> Train: 0.6691 | Val: 0.7102 | F1: 0.6494\n",
      "Epoch 4/15 -> Train: 0.6485 | Val: 0.6902 | F1: 0.6860\n",
      "Epoch 5/15 -> Train: 0.6307 | Val: 0.6818 | F1: 0.6756\n",
      "Epoch 6/15 -> Train: 0.6170 | Val: 0.6854 | F1: 0.6863\n",
      "Epoch 7/15 -> Train: 0.6009 | Val: 0.6973 | F1: 0.6705\n",
      "Epoch 8/15 -> Train: 0.5859 | Val: 0.6941 | F1: 0.6697\n",
      "Epoch 9/15 -> Train: 0.5541 | Val: 0.7115 | F1: 0.6532\n",
      "Epoch 10/15 -> Train: 0.5384 | Val: 0.7274 | F1: 0.6586\n",
      "Early stopping at epoch 10\n",
      "New best model: lstm_unidirectional_h128_d0.2\n",
      "\n",
      "==================================================\n",
      "Experiment: lstm_wide_h512_d0.4\n",
      "Parameters: 8,820,742\n",
      "Epoch 1/15 -> Train: 0.9807 | Val: 0.8683 | F1: 0.5485\n",
      "Epoch 2/15 -> Train: 0.7452 | Val: 0.7925 | F1: 0.5969\n",
      "Epoch 3/15 -> Train: 0.7056 | Val: 0.7804 | F1: 0.6125\n",
      "Epoch 4/15 -> Train: 0.6822 | Val: 0.7450 | F1: 0.6282\n",
      "Epoch 5/15 -> Train: 0.6718 | Val: 0.7251 | F1: 0.6418\n",
      "Epoch 6/15 -> Train: 0.6651 | Val: 0.7240 | F1: 0.6759\n",
      "Epoch 7/15 -> Train: 0.6536 | Val: 0.7277 | F1: 0.6633\n",
      "Epoch 8/15 -> Train: 0.6498 | Val: 0.6997 | F1: 0.6786\n",
      "Epoch 9/15 -> Train: 0.6422 | Val: 0.7193 | F1: 0.6431\n",
      "Epoch 10/15 -> Train: 0.6367 | Val: 0.7111 | F1: 0.6607\n",
      "Epoch 11/15 -> Train: 0.6315 | Val: 0.7096 | F1: 0.6584\n",
      "Epoch 12/15 -> Train: 0.6193 | Val: 0.7030 | F1: 0.6835\n",
      "Epoch 13/15 -> Train: 0.6178 | Val: 0.7069 | F1: 0.6704\n",
      "Early stopping at epoch 13\n",
      "\n",
      "==================================================\n",
      "Best validation loss: 0.6818\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "lstm_results = []\n",
    "best_overall_val_loss = float('inf')\n",
    "\n",
    "for config in lstm_experiment_configs:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Experiment: {config['experiment_name']}\")\n",
    "\n",
    "    model = LSTMEmpathyNet(config).to(device)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Parameters: {total_params:,}\")\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "\n",
    "    best_epoch_metrics = {\"val_loss\": float('inf')}\n",
    "    patience_counter = 0\n",
    "    early_stopping_patience = 5\n",
    "\n",
    "    for epoch in range(NUM_LSTM_EPOCHS):\n",
    "        train_loss = train_lstm_one_epoch(model, lstm_train_loader, optimizer, loss_functions, device)\n",
    "        val_metrics = evaluate_lstm_performance(model, lstm_eval_loader, loss_functions, device)\n",
    "\n",
    "        scheduler.step(val_metrics['val_loss'])\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{NUM_LSTM_EPOCHS} -> Train: {train_loss:.4f} | Val: {val_metrics['val_loss']:.4f} | F1: {val_metrics['polarity_f1']:.4f}\")\n",
    "\n",
    "        if val_metrics['val_loss'] < best_epoch_metrics['val_loss']:\n",
    "            best_epoch_metrics = val_metrics\n",
    "            model_save_path = os.path.join(LSTM_MODELS_SAVE_PATH, f\"{config['experiment_name']}_best.pth\")\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    final_result = {\n",
    "        \"experiment_name\": config['experiment_name'],\n",
    "        \"model_path\": model_save_path,\n",
    "        \"hidden_dim\": config['hidden_dim'],\n",
    "        \"num_layers\": config['num_layers'],\n",
    "        \"bidirectional\": config['bidirectional'],\n",
    "        \"dropout\": config['dropout'],\n",
    "        \"learning_rate\": config['learning_rate'],\n",
    "        \"total_params\": total_params\n",
    "    }\n",
    "    final_result.update(best_epoch_metrics)\n",
    "    lstm_results.append(final_result)\n",
    "\n",
    "    if best_epoch_metrics['val_loss'] < best_overall_val_loss:\n",
    "        best_overall_val_loss = best_epoch_metrics['val_loss']\n",
    "        print(f\"New best model: {config['experiment_name']}\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Best validation loss: {best_overall_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419cc1c8",
   "metadata": {
    "id": "419cc1c8"
   },
   "source": [
    "## Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81f331d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "81f331d5",
    "outputId": "d978951c-bb10-4fab-d6db-1cab89a4fe42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Experiment Results:\n",
      "                   Experiment  Hidden  Layers  Bidir  Dropout  Val Loss  Int MAE  Emp MAE   Pol F1\n",
      "lstm_unidirectional_h128_d0.2     128       2  False      0.2  0.681776 0.500202 0.738660 0.675564\n",
      "          lstm_wide_h512_d0.4     512       2   True      0.4  0.699658 0.493168 0.743910 0.678621\n",
      "      lstm_baseline_h128_d0.3     128       2   True      0.3  0.700002 0.490881 0.755700 0.681496\n",
      "          lstm_deep_h256_d0.5     256       3   True      0.5  0.701584 0.500063 0.742865 0.665044\n",
      "\n",
      "Best model: lstm_unidirectional_h128_d0.2\n",
      "Val Loss: 0.6818\n",
      "Intensity MAE: 0.5002\n",
      "Empathy MAE: 0.7387\n",
      "Polarity F1: 0.6756\n"
     ]
    }
   ],
   "source": [
    "lstm_results_df = pd.DataFrame(lstm_results)\n",
    "\n",
    "lstm_display_columns = {\n",
    "    'experiment_name': 'Experiment',\n",
    "    'hidden_dim': 'Hidden',\n",
    "    'num_layers': 'Layers',\n",
    "    'bidirectional': 'Bidir',\n",
    "    'dropout': 'Dropout',\n",
    "    'val_loss': 'Val Loss',\n",
    "    'intensity_mae': 'Int MAE',\n",
    "    'empathy_mae': 'Emp MAE',\n",
    "    'polarity_f1': 'Pol F1'\n",
    "}\n",
    "\n",
    "lstm_results_display = lstm_results_df[list(lstm_display_columns.keys())].rename(columns=lstm_display_columns)\n",
    "lstm_results_sorted = lstm_results_display.sort_values(by=\"Val Loss\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "REPORT_PATH = os.path.join(ROOT_PATH, 'Report')\n",
    "os.makedirs(REPORT_PATH, exist_ok=True)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d\")\n",
    "lstm_report_filepath = os.path.join(REPORT_PATH, f\"lstm_results_{timestamp}.csv\")\n",
    "lstm_results_sorted.to_csv(lstm_report_filepath, index=False)\n",
    "\n",
    "print(\"LSTM Experiment Results:\")\n",
    "print(lstm_results_sorted.to_string(index=False))\n",
    "\n",
    "best_experiment_name = lstm_results_sorted.iloc[0]['Experiment']\n",
    "best_experiment_full_info = next(item for item in lstm_results if item[\"experiment_name\"] == best_experiment_name)\n",
    "\n",
    "print(f\"\\nBest model: {best_experiment_full_info['experiment_name']}\")\n",
    "print(f\"Val Loss: {best_experiment_full_info['val_loss']:.4f}\")\n",
    "print(f\"Intensity MAE: {best_experiment_full_info['intensity_mae']:.4f}\")\n",
    "print(f\"Empathy MAE: {best_experiment_full_info['empathy_mae']:.4f}\")\n",
    "print(f\"Polarity F1: {best_experiment_full_info['polarity_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800cc08f",
   "metadata": {
    "id": "800cc08f"
   },
   "source": [
    "## Evaluation on Dev Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2519cfe2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2519cfe2",
    "outputId": "41012e0b-3270-4b23-d108-ef552f55b54b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGRESSION METRICS\n",
      "\n",
      "Emotion Intensity:\n",
      "  MAE: 0.5002\n",
      "  MSE: 0.4325\n",
      "  R²: 0.2262\n",
      "\n",
      "Empathy:\n",
      "  MAE: 0.7387\n",
      "  MSE: 0.8108\n",
      "  R²: 0.3253\n",
      "\n",
      "CLASSIFICATION METRICS\n",
      "\n",
      "Emotional Polarity:\n",
      "  Accuracy: 0.6859\n",
      "  Precision: 0.6973\n",
      "  Recall: 0.6859\n",
      "  F1-Score: 0.6756\n",
      "\n",
      "Confusion Matrix:\n",
      "  [54 87 16]\n",
      "  [ 14 360  74]\n",
      "  [  5 114 263]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.74      0.34      0.47       157\n",
      "     Class 1       0.64      0.80      0.71       448\n",
      "     Class 2       0.75      0.69      0.72       382\n",
      "\n",
      "    accuracy                           0.69       987\n",
      "   macro avg       0.71      0.61      0.63       987\n",
      "weighted avg       0.70      0.69      0.68       987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model_config = next(config for config in lstm_experiment_configs\n",
    "                         if config[\"experiment_name\"] == best_experiment_name)\n",
    "best_lstm_model = LSTMEmpathyNet(best_model_config).to(device)\n",
    "best_lstm_model.load_state_dict(torch.load(best_experiment_full_info['model_path']))\n",
    "best_lstm_model.eval()\n",
    "\n",
    "all_intensity_preds, all_intensity_labels = [], []\n",
    "all_empathy_preds, all_empathy_labels = [], []\n",
    "all_polarity_preds, all_polarity_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in lstm_eval_loader:\n",
    "        features = batch['features'].to(device)\n",
    "        # Calculate lengths based on features (assuming 0 is padding)\n",
    "        lengths = (features.sum(dim=2) != 0).sum(dim=1).to(device)\n",
    "        # Ensure lengths are at least 1\n",
    "        lengths = torch.clamp(lengths, min=1)\n",
    "        labels = {k: v.to(device) for k, v in batch['labels'].items()}\n",
    "\n",
    "        outputs = best_lstm_model(features, lengths)\n",
    "\n",
    "        all_intensity_preds.append(outputs['intensity'].cpu())\n",
    "        all_intensity_labels.append(labels['intensity'].cpu())\n",
    "        all_empathy_preds.append(outputs['empathy'].cpu())\n",
    "        all_empathy_labels.append(labels['empathy'].cpu())\n",
    "\n",
    "        polarity_preds = torch.argmax(outputs['polarity'], dim=1)\n",
    "        all_polarity_preds.append(polarity_preds.cpu())\n",
    "        all_polarity_labels.append(labels['polarity'].cpu())\n",
    "\n",
    "all_intensity_preds = torch.cat(all_intensity_preds).numpy()\n",
    "all_intensity_labels = torch.cat(all_intensity_labels).numpy()\n",
    "all_empathy_preds = torch.cat(all_empathy_preds).numpy()\n",
    "all_empathy_labels = torch.cat(all_empathy_labels).numpy()\n",
    "all_polarity_preds = torch.cat(all_polarity_preds).numpy()\n",
    "all_polarity_labels = torch.cat(all_polarity_labels).numpy()\n",
    "\n",
    "print(\"REGRESSION METRICS\")\n",
    "print(f\"\\nEmotion Intensity:\")\n",
    "print(f\"  MAE: {mean_absolute_error(all_intensity_labels, all_intensity_preds):.4f}\")\n",
    "print(f\"  MSE: {mean_squared_error(all_intensity_labels, all_intensity_preds):.4f}\")\n",
    "print(f\"  R²: {r2_score(all_intensity_labels, all_intensity_preds):.4f}\")\n",
    "\n",
    "print(f\"\\nEmpathy:\")\n",
    "print(f\"  MAE: {mean_absolute_error(all_empathy_labels, all_empathy_preds):.4f}\")\n",
    "print(f\"  MSE: {mean_squared_error(all_empathy_labels, all_empathy_preds):.4f}\")\n",
    "print(f\"  R²: {r2_score(all_empathy_labels, all_empathy_preds):.4f}\")\n",
    "\n",
    "print(f\"\\nCLASSIFICATION METRICS\")\n",
    "print(f\"\\nEmotional Polarity:\")\n",
    "polarity_accuracy = accuracy_score(all_polarity_labels, all_polarity_preds)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_polarity_labels, all_polarity_preds, average='weighted', zero_division=0)\n",
    "print(f\"  Accuracy: {polarity_accuracy:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall: {recall:.4f}\")\n",
    "print(f\"  F1-Score: {f1:.4f}\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(all_polarity_labels, all_polarity_preds)\n",
    "for i in range(cm.shape[0]):\n",
    "    print(f\"  {cm[i]}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "# Assuming the classes present are 0, 1, 2 based on the confusion matrix size\n",
    "present_classes = sorted(list(set(all_polarity_labels).union(set(all_polarity_preds))))\n",
    "target_names = [f'Class {c}' for c in present_classes]\n",
    "print(classification_report(all_polarity_labels, all_polarity_preds,\n",
    "                           target_names=target_names, labels=present_classes, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1ee16e",
   "metadata": {
    "id": "4d1ee16e"
   },
   "source": [
    "## Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "308d0f72",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "308d0f72",
    "outputId": "33412d58-d949-4a08-e48a-a8098da6b810"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions on test set...\n",
      "Generating sequence embeddings for 2311 test samples...\n",
      "Submission file created: /content/drive/MyDrive/NLPproject1/Report/lstm_report.csv\n",
      "\n",
      "Preview:\n",
      "   id   Emotion  EmotionalPolarity   Empathy\n",
      "0   1  2.175447                  1  1.911928\n",
      "1   2  2.437121                  2  2.494642\n",
      "2   3  2.269280                  2  2.163032\n",
      "3   4  2.258986                  2  2.234717\n",
      "4   5  2.344783                  2  2.296820\n",
      "5   6  2.815558                  2  2.662120\n",
      "6   7  1.875809                  1  2.007888\n",
      "7   8  2.217818                  1  2.184005\n",
      "8   9  1.969614                  1  1.774307\n",
      "9  10  1.852713                  1  1.812997\n"
     ]
    }
   ],
   "source": [
    "TEST_CSV_PATH = f\"{DATA_PATH}/trac2_CONVT_test.csv\"\n",
    "LSTM_SUBMISSION_PATH = os.path.join(REPORT_PATH, 'lstm_report.csv')\n",
    "\n",
    "print(\"Running predictions on test set...\")\n",
    "\n",
    "test_dataset = RNNInferenceDataset(\n",
    "    TEST_CSV_PATH,\n",
    "    sequence_embedder,\n",
    "    id_column='id',\n",
    "    text_column='text'\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=LSTM_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "all_ids = []\n",
    "all_emotion_preds = []\n",
    "all_empathy_preds = []\n",
    "all_polarity_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        ids = batch['id']\n",
    "        features = batch['features'].to(device)\n",
    "        # Calculate lengths based on features (assuming 0 is padding)\n",
    "        lengths = (features.sum(dim=2) != 0).sum(dim=1).to(device)\n",
    "        # Ensure lengths are at least 1\n",
    "        lengths = torch.clamp(lengths, min=1)\n",
    "\n",
    "        outputs = best_lstm_model(features, lengths)\n",
    "\n",
    "        emotion_preds = outputs['intensity'].squeeze().cpu().numpy()\n",
    "        empathy_preds = outputs['empathy'].squeeze().cpu().numpy()\n",
    "        polarity_preds = torch.argmax(outputs['polarity'], dim=1).cpu().numpy()\n",
    "\n",
    "        all_ids.extend(ids.numpy())\n",
    "        all_emotion_preds.extend(emotion_preds)\n",
    "        all_empathy_preds.extend(empathy_preds)\n",
    "        all_polarity_preds.extend(polarity_preds)\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': all_ids,\n",
    "    'Emotion': all_emotion_preds,\n",
    "    'EmotionalPolarity': all_polarity_preds,\n",
    "    'Empathy': all_empathy_preds\n",
    "})\n",
    "\n",
    "submission_df['EmotionalPolarity'] = submission_df['EmotionalPolarity'].astype(int)\n",
    "submission_df.to_csv(LSTM_SUBMISSION_PATH, index=False)\n",
    "\n",
    "print(f\"Submission file created: {LSTM_SUBMISSION_PATH}\")\n",
    "print(f\"\\nPreview:\")\n",
    "print(submission_df.head(10))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
